# 6、如何解决消息队列的延时以及过期失效问题 消息队列满了之后该如何处理 有几百万的消息持续积压几小时,说说如何解决

方案分析

该问题,其本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。另外还有可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq 设置了消息过期时间后就没了怎么办？

所以这种问题线上常见的，一般不出，一出就是大问题，一般常见于，举个例子，消费端每次消费之后要写mysql，结果mysql 挂了，消费端挂掉了。导致消费速度极其慢。

分析1+话术

这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复consumer 的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。(可行,但是不建议在面试的时候说)

一个消费者一秒是1000 条，一秒3 个消费者是3000 条，一分钟是18 万条，1000 多万条

所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1 小时的时间才能恢复过来

一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：

1） 先修复consumer 的问题，确保其恢复消费速度，然后将现有cnosumer 都停掉

2） 新建一个topic，partition 是原来的10 倍，临时建立好原先10 倍或者20 倍的

queue 数量

3） 然后写一个临时的分发数据的consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10 倍数量的queue

4） 接着临时征用10 倍的机器来部署consumer，每一批consumer 消费一个临时

queue 的数据

5） 这种做法相当于是临时将queue 资源和consumer 资源扩大10 倍，以正常的10

倍速度来消费数据

6） 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer 机器来消费消息

分析2+话术

rabbitmq 是可以设置过期时间的，就是TTL，如果消息在queue 中积压超过一定的时间就会被rabbitmq 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq 里，而是大量的数据会直接搞丢。

这个情况下，就不是说要增加consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12 点以后，用户都睡觉了。

这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq 里面去，把白天丢的数据给他补回来。也只能是这样了。

假设1 万个订单积压在mq 里面，没有处理，其中1000 个订单都丢了，你只能手动写程序把那1000 个订单给查出来，手动发到mq 里去再补一次

分析3+话术

如果走的方式是消息积压在mq 里，那么如果你很长时间都没处理掉，此时导致mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了， 你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

> 更新: 2024-05-01 16:33:04  
